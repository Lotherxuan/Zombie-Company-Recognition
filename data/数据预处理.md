### 简要介绍一下数据清洗的过程 （update date:2/23)

大体思路是先将八份数据集全部混在一起，涉及到同一特征值在三年的时间轴上出现三次的情况就将三年中每一年的特征值都单独作为一维的特征，如此得到了文件 **/data/data_process/data.ANSI.csv ** 转换为ANSI编码主要是便于在excel中打开而不出现乱码。



对于 **data_ANSI.csv** 中出现的**企业类型**、**控制人类型**、**行业**这三个特征值采取one-hot编码得到文件 **data_with_na.csv**



然后删除**data_with_na.csv** 中的 **控制人ID**、**区域**这两个特征值，姑且认为各地区出现僵尸企业的概率均等，区域不影响对于僵尸企业的判断

----

以上数据处理过程的文件被我不小心搞丢了...现有的数据处理的文件 **data_process.ipynb**只有以下很少一部分数据处理的过程

---

然后删除所有出现特征值中出现na的样本，大概一共剩下17000+的样本

